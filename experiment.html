<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Client-Side ONNX Video Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
      body {
        font-family: sans-serif;
        padding: 20px;
      }
      .container {
        position: relative;
        display: inline-block;
      }
      video {
        display: block;
        max-width: 100%;
        border: 1px solid #ccc;
      }
      canvas {
        position: absolute;
        top: 0;
        left: 0;
        pointer-events: none;
      }
      .controls {
        margin-bottom: 20px;
        background: #f0f0f0;
        padding: 15px;
        border-radius: 8px;
      }
    </style>
  </head>
  <body>
    <h1>ðŸš€ Client-Side ONNX Video Detector</h1>

    <div class="controls">
      <!--       <h3>1. Setup</h3>
      <label
        >Upload ONNX Model:
        <input type="file" id="modelInput" accept=".onnx" /></label
      ><br /><br />
      <label
        >Upload Video: <input type="file" id="videoInput" accept="video/*"
      /></label>
       -->
      <p id="status">Status: Waiting for inputs...</p>
    </div>

    <div class="container">
      <video id="video" width="1140" height="640" controls muted></video>
      <canvas id="canvas" width="1140" height="640"></canvas>
    </div>

    <script>
      // --- CONFIGURATION ---
      const MODEL_INPUT_SIZE = 640;
      const CONFIDENCE_THRESHOLD = 0.5;

      // COCO Class Names (Standard YOLO)
      let labels = [
        "person",
        "bicycle",
        "car",
        "motorcycle",
        "airplane",
        "bus",
        "train",
        "truck",
        "boat",
        "traffic light",
        "fire hydrant",
        "stop sign",
        "parking meter",
        "bench",
        "bird",
        "cat",
        "dog",
        "horse",
        "sheep",
        "cow",
        "elephant",
        "bear",
        "zebra",
        "giraffe",
        "backpack",
        "umbrella",
        "handbag",
        "tie",
        "suitcase",
        "frisbee",
        "skis",
        "snowboard",
        "sports ball",
        "kite",
        "baseball bat",
        "baseball glove",
        "skateboard",
        "surfboard",
        "tennis racket",
        "bottle",
        "wine glass",
        "cup",
        "fork",
        "knife",
        "spoon",
        "bowl",
        "banana",
        "apple",
        "sandwich",
        "orange",
        "broccoli",
        "carrot",
        "hot dog",
        "pizza",
        "donut",
        "cake",
        "chair",
        "couch",
        "potted plant",
        "bed",
        "dining table",
        "toilet",
        "tv",
        "laptop",
        "mouse",
        "remote",
        "keyboard",
        "cell phone",
        "microwave",
        "oven",
        "toaster",
        "sink",
        "refrigerator",
        "book",
        "clock",
        "vase",
        "scissors",
        "teddy bear",
        "hair drier",
        "toothbrush",
      ];

      // labels = [
      //   "ball",
      //   "ball in basket",
      //   "player",
      //   "basket",
      //   "player_shooting",
      // ];

      // --- GLOBAL VARIABLES ---
      let session = null;
      let isProcessing = false;
      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");
      const ctx = canvas.getContext("2d");
      const status = document.getElementById("status");

      //   // --- 1. LOAD MODEL ---
      //   document
      //     .getElementById("modelInput")
      //     .addEventListener("change", async (e) => {
      //       const file = e.target.files[0];
      //       if (!file) return;

      //       status.textContent =
      //         "Status: Loading model... (this may take a moment)";

      //       try {
      //         const buffer = await file.arrayBuffer();
      //         session = await ort.InferenceSession.create(buffer, {
      //           executionProviders: ["webgpu"], // ["webgpu", "webgl", "wasm"],
      //         });
      //         status.textContent = "Status: âœ… Model Loaded! Now upload a video.";
      //       } catch (err) {
      //         status.textContent = `Status: âŒ Error loading model: ${err.message}`;
      //         console.error(err);
      //       }
      //     });

      //   // --- 2. LOAD VIDEO ---
      //   document.getElementById("videoInput").addEventListener("change", (e) => {
      //     const file = e.target.files[0];
      //     if (file) {
      //       const url = URL.createObjectURL(file);
      //       video.src = url;
      //       status.textContent =
      //         "Status: Video ready. Play the video to start detection.";
      //     }
      //   });

      const MODEL_PATH = "./yolo11n-detect.onnx"; // Change to your model filename
      const VIDEO_PATH = "./basket-sp.mp4"; // Change to your video filename

      // --- 1. AUTO-INIT ON LOAD ---
      window.onload = async () => {
        try {
          status.textContent = "Status: Downloading Model & Video...";

          // A. Load Model via Fetch
          const modelResponse = await fetch(MODEL_PATH);
          const modelBuffer = await modelResponse.arrayBuffer();

          // Initialize Session (Try WebGPU -> WebGL -> WASM)
          session = await ort.InferenceSession.create(modelBuffer, {
            executionProviders: ["webgpu", "webgl", "wasm"],
          });

          // B. Set Video Source
          video.src = VIDEO_PATH;

          // Wait for video metadata (to set canvas size)
          video.onloadedmetadata = () => {
            canvas.width = video.clientWidth;
            canvas.height = video.clientHeight;
            status.textContent = "Status: Ready! Click Start.";
            startBtn.disabled = false;
          };
        } catch (err) {
          status.textContent = `Status: âŒ Error: ${err.message}. (Did you run a local server?)`;
          console.error(err);
        }
      };

      // --- 3. MAIN LOOP HANDLERS ---
      video.addEventListener("play", () => {
        // Only start the loop if we aren't already processing
        if (!isProcessing) {
          canvas.width = video.clientWidth;
          canvas.height = video.clientHeight;
          isProcessing = true;
          processFrame();
        }
      });

      video.addEventListener("ended", () => {
        isProcessing = false;
      });

      // --- 4. CORE PROCESSING LOOP (Modified) ---
      async function processFrame() {
        if (!isProcessing || !session || video.ended) return;

        // A. PAUSE Video & Start Timer
        // video.pause();
        const startTime = performance.now();

        try {
          // B. Preprocess
          const inputTensor = await preprocess(video);

          // C. Inference
          const feeds = {};
          feeds[session.inputNames[0]] = inputTensor;
          const results = await session.run(feeds);

          // D. Postprocess & Draw
          const outputName = session.outputNames[0];
          const outputTensor = results[outputName];
          drawDetections(outputTensor);
        } catch (err) {
          console.error("Inference error:", err);
          isProcessing = false;
          return; // Stop loop on error
        }

        // E. End Timer & Log
        const endTime = performance.now();
        const duration = (endTime - startTime).toFixed(2);
        console.log(`Frame processed in: ${duration} ms`);

        // F. RESUME Video & Loop
        // We play the video, then immediately request the next frame check.
        // The browser will render the next video frame, then hit this loop again.
        try {
          //   await video.play();
          requestAnimationFrame(processFrame);
        } catch (e) {
          // Handle case where play() is interrupted
          console.log("Playback interrupted");
        }
      }

      // --- 5. PRE-PROCESSING ---
      async function preprocess(videoSource) {
        const offScreenCanvas = document.createElement("canvas");
        offScreenCanvas.width = MODEL_INPUT_SIZE;
        offScreenCanvas.height = MODEL_INPUT_SIZE;
        const ctx = offScreenCanvas.getContext("2d");
        ctx.drawImage(videoSource, 0, 0, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE);

        const imageData = ctx.getImageData(
          0,
          0,
          MODEL_INPUT_SIZE,
          MODEL_INPUT_SIZE
        );
        const { data } = imageData;
        const float32Data = new Float32Array(
          3 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE
        );

        for (let i = 0; i < data.length / 4; i++) {
          const r = data[i * 4] / 255.0;
          const g = data[i * 4 + 1] / 255.0;
          const b = data[i * 4 + 2] / 255.0;
          float32Data[i] = r;
          float32Data[i + MODEL_INPUT_SIZE * MODEL_INPUT_SIZE] = g;
          float32Data[i + 2 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE] = b;
        }
        return new ort.Tensor("float32", float32Data, [
          1,
          3,
          MODEL_INPUT_SIZE,
          MODEL_INPUT_SIZE,
        ]);
      }

      // --- 6. POST-PROCESSING (YOLOv11/v8 Logic) ---
      function drawDetections(output) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        const data = output.data;
        const dims = output.dims; // [1, 84, 8400]
        const numClasses = dims[1] - 4;
        const numAnchors = dims[2];

        const scaleX = canvas.width / MODEL_INPUT_SIZE;
        const scaleY = canvas.height / MODEL_INPUT_SIZE;

        const boxes = [];

        for (let i = 0; i < numAnchors; i++) {
          let maxScore = -Infinity;
          let classIndex = -1;

          for (let c = 0; c < numClasses; c++) {
            const row = c + 4;
            const score = data[row * numAnchors + i];
            if (score > maxScore) {
              maxScore = score;
              classIndex = c;
            }
          }

          if (maxScore > CONFIDENCE_THRESHOLD) {
            // FILTER: Only allow Person (0) and Sports Ball (32)
            // if (classIndex === 0 || classIndex === 32) {
            const cx = data[0 * numAnchors + i];
            const cy = data[1 * numAnchors + i];
            const w = data[2 * numAnchors + i];
            const h = data[3 * numAnchors + i];

            const x1 = (cx - w / 2) * scaleX;
            const y1 = (cy - h / 2) * scaleY;
            const x2 = (cx + w / 2) * scaleX;
            const y2 = (cy + h / 2) * scaleY;

            boxes.push([x1, y1, x2, y2, classIndex, maxScore]);
            // }
          }
        }

        const selectedBoxes = nms(boxes, 0.45);

        selectedBoxes.forEach((box) => {
          const [x1, y1, x2, y2, classIdx, score] = box;
          const color = getColor(classIdx);
          const labelName = labels[classIdx] || "Unknown";

          ctx.strokeStyle = color;
          ctx.lineWidth = 3;
          ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

          const text = `${labelName} ${(score * 100).toFixed(1)}%`;
          ctx.font = "16px Arial";
          const textWidth = ctx.measureText(text).width;
          ctx.fillStyle = color;
          ctx.fillRect(x1, y1 - 20, textWidth + 10, 20);
          ctx.fillStyle = "#FFFFFF";
          ctx.fillText(text, x1 + 5, y1 - 5);
        });
      }

      function nms(boxes, iouThreshold) {
        if (boxes.length === 0) return [];
        boxes.sort((a, b) => b[5] - a[5]);
        const result = [];
        while (boxes.length > 0) {
          const best = boxes.shift();
          result.push(best);
          boxes = boxes.filter(
            (other) => calculateIoU(best, other) < iouThreshold
          );
        }
        return result;
      }

      function calculateIoU(boxA, boxB) {
        const xA = Math.max(boxA[0], boxB[0]);
        const yA = Math.max(boxA[1], boxB[1]);
        const xB = Math.min(boxA[2], boxB[2]);
        const yB = Math.min(boxA[3], boxB[3]);
        const intersectionArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
        const areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]);
        const areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]);
        return intersectionArea / (areaA + areaB - intersectionArea);
      }

      function getColor(index) {
        const colors = [
          "#FF0000",
          "#00FF00",
          "#0000FF",
          "#000000",
          "#00FFFF",
          "#FF00FF",
          "#FFA500",
        ];
        return colors[index % colors.length];
      }
    </script>
  </body>
</html>
