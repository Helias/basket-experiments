<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Client-Side ONNX Video Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
      body {
        font-family: sans-serif;
        padding: 20px;
      }
      .container {
        position: relative;
        display: inline-block;
      }
      video {
        display: block;
        max-width: 100%;
        border: 1px solid #ccc;
      }
      canvas {
        position: absolute;
        top: 0;
        left: 0;
        pointer-events: none;
      }
      .controls {
        margin-bottom: 20px;
        background: #f0f0f0;
        padding: 15px;
        border-radius: 8px;
      }
    </style>
  </head>
  <body>
    <h1>ðŸš€ Client-Side ONNX Video Detector</h1>

    <div class="controls">
      <!--       <h3>1. Setup</h3>
      <label
        >Upload ONNX Model:
        <input type="file" id="modelInput" accept=".onnx" /></label
      ><br /><br />
      <label
        >Upload Video: <input type="file" id="videoInput" accept="video/*"
      /></label>
       -->
      <label style="display: block; margin-bottom: 10px">
        <input type="checkbox" id="useWorkerCheckbox" checked />
        Use Web Worker (uncheck for main thread comparison)
      </label>
      <p id="status">Status: Waiting for inputs...</p>
    </div>

    <div class="container">
      <video id="video" width="1140" height="640" controls muted></video>
      <canvas id="canvas" width="1140" height="640"></canvas>
    </div>

    <script>
      // --- CONFIGURATION ---
      const MODEL_INPUT_SIZE = 640;
      const CONFIDENCE_THRESHOLD = 0.5;

      // COCO Class Names (Standard YOLO)
      let labels = [
        "person",
        "bicycle",
        "car",
        "motorcycle",
        "airplane",
        "bus",
        "train",
        "truck",
        "boat",
        "traffic light",
        "fire hydrant",
        "stop sign",
        "parking meter",
        "bench",
        "bird",
        "cat",
        "dog",
        "horse",
        "sheep",
        "cow",
        "elephant",
        "bear",
        "zebra",
        "giraffe",
        "backpack",
        "umbrella",
        "handbag",
        "tie",
        "suitcase",
        "frisbee",
        "skis",
        "snowboard",
        "sports ball",
        "kite",
        "baseball bat",
        "baseball glove",
        "skateboard",
        "surfboard",
        "tennis racket",
        "bottle",
        "wine glass",
        "cup",
        "fork",
        "knife",
        "spoon",
        "bowl",
        "banana",
        "apple",
        "sandwich",
        "orange",
        "broccoli",
        "carrot",
        "hot dog",
        "pizza",
        "donut",
        "cake",
        "chair",
        "couch",
        "potted plant",
        "bed",
        "dining table",
        "toilet",
        "tv",
        "laptop",
        "mouse",
        "remote",
        "keyboard",
        "cell phone",
        "microwave",
        "oven",
        "toaster",
        "sink",
        "refrigerator",
        "book",
        "clock",
        "vase",
        "scissors",
        "teddy bear",
        "hair drier",
        "toothbrush",
      ];

      // labels = [
      //   "ball",
      //   "ball in basket",
      //   "player",
      //   "basket",
      //   "player_shooting",
      // ];

      // --- GLOBAL VARIABLES ---
      let session = null;
      let isProcessing = false;
      const video = document.getElementById("video");
      const canvas = document.getElementById("canvas");
      const ctx = canvas.getContext("2d");
      const status = document.getElementById("status");

      // Performance comparison flag
      let useWebWorker = document.getElementById("useWorkerCheckbox").checked;

      // Web Worker & Job Queue
      let worker = null;
      let jobQueue = [];
      let processingJobs = new Map();
      let frameIdCounter = 0;
      let maxConcurrentJobs = 3;
      let maxQueueSize = 10;
      let lastDisplayedFrameId = -1;
      let isWorkerReady = false;

      //   // --- 1. LOAD MODEL ---
      //   document
      //     .getElementById("modelInput")
      //     .addEventListener("change", async (e) => {
      //       const file = e.target.files[0];
      //       if (!file) return;

      //       status.textContent =
      //         "Status: Loading model... (this may take a moment)";

      //       try {
      //         const buffer = await file.arrayBuffer();
      //         session = await ort.InferenceSession.create(buffer, {
      //           executionProviders: ["webgpu"], // ["webgpu", "webgl", "wasm"],
      //         });
      //         status.textContent = "Status: âœ… Model Loaded! Now upload a video.";
      //       } catch (err) {
      //         status.textContent = `Status: âŒ Error loading model: ${err.message}`;
      //         console.error(err);
      //       }
      //     });

      //   // --- 2. LOAD VIDEO ---
      //   document.getElementById("videoInput").addEventListener("change", (e) => {
      //     const file = e.target.files[0];
      //     if (file) {
      //       const url = URL.createObjectURL(file);
      //       video.src = url;
      //       status.textContent =
      //         "Status: Video ready. Play the video to start detection.";
      //     }
      //   });

      const MODEL_PATH = "./yolo11n-detect.onnx"; // Change to your model filename
      const VIDEO_PATH = "./basket-sp.mp4"; // Change to your video filename

      // Listen to checkbox changes
      document.addEventListener("DOMContentLoaded", () => {
        const checkbox = document.getElementById("useWorkerCheckbox");
        useWebWorker = checkbox.checked;
        checkbox.addEventListener("change", (e) => {
          alert("Please reload the page for mode change to take effect.");
        });
      });

      // --- 1. AUTO-INIT ON LOAD ---
      window.onload = async () => {
        try {
          const checkbox = document.getElementById("useWorkerCheckbox");
          useWebWorker = checkbox.checked;

          if (useWebWorker) {
            status.textContent = "Status: Initializing Web Worker...";
            worker = new Worker("./detection-worker.js");

            // Setup worker message handler
            worker.onmessage = handleWorkerMessage;
            worker.onerror = (error) => {
              status.textContent = `Worker Error: ${error.message}`;
              console.error("Worker error:", error);
            };

            // B. Initialize model in worker
            worker.postMessage({
              type: "INIT",
              data: { modelPath: MODEL_PATH },
            });
          } else {
            // Main Thread Mode
            status.textContent = "Status: Loading model on main thread...";
            const modelResponse = await fetch(MODEL_PATH);
            const modelBuffer = await modelResponse.arrayBuffer();

            session = await ort.InferenceSession.create(modelBuffer, {
              executionProviders: ["webgl", "wasm"],
              graphOptimizationLevel: "all",
            });

            console.log("[Main Thread] Model loaded");
          }

          // C. Set Video Source
          video.src = VIDEO_PATH;

          // Wait for video metadata
          video.onloadedmetadata = () => {
            canvas.width = video.clientWidth;
            canvas.height = video.clientHeight;
            if (useWebWorker && isWorkerReady) {
              status.textContent = "Status: Ready! Play video (Worker mode)";
            } else if (!useWebWorker) {
              status.textContent =
                "Status: Ready! Play video (Main Thread mode)";
            }
          };
        } catch (err) {
          status.textContent = `Status: âŒ Error: ${err.message}`;
          console.error(err);
        }
      };

      // Handle messages from worker
      function handleWorkerMessage(e) {
        const { type, frameId, output, processingTime, error } = e.data;

        switch (type) {
          case "MODEL_LOADED":
            isWorkerReady = true;
            status.textContent = "Status: Ready! Play video (Worker mode)";
            console.log("Worker ready with model");
            break;

          case "FRAME_PROCESSED":
            // Draw only newest frames
            if (output && frameId > lastDisplayedFrameId) {
              drawDetections({
                data: new Float32Array(output.data),
                dims: output.dims,
              });
              lastDisplayedFrameId = frameId;
              // console.log(`Frame ${frameId} displayed (${processingTime}ms)`);
            }

            // Remove from processing queue
            processingJobs.delete(frameId);

            // Process next job
            processNextJob();
            break;

          case "ERROR":
            console.error("Worker error:", error);
            if (frameId !== undefined) {
              processingJobs.delete(frameId);
              processNextJob();
            }
            break;
        }
      }

      // Process next job from queue
      function processNextJob() {
        while (jobQueue.length > 0 && processingJobs.size < maxConcurrentJobs) {
          const job = jobQueue.shift();
          processingJobs.set(job.frameId, job);

          worker.postMessage({
            type: "PROCESS_FRAME",
            data: job,
          });

          // console.log(
          //   `Processing frame ${job.frameId} (${processingJobs.size}/${maxConcurrentJobs} busy, ${jobQueue.length} queued)`
          // );
        }
      }

      // Add job to queue
      function enqueueJob(imageData) {
        const frameId = frameIdCounter++;

        // Drop old frames if queue is full
        if (jobQueue.length >= maxQueueSize) {
          const dropped = jobQueue.shift();
          // console.log(`Dropped frame ${dropped.frameId} (queue full)`);
        }

        const job = {
          frameId,
          timestamp: video.currentTime,
          imageData,
        };

        jobQueue.push(job);
        processNextJob();
      }

      // --- 3. MAIN LOOP HANDLERS ---
      video.addEventListener("play", () => {
        // Only start the loop if we aren't already processing
        if (!isProcessing) {
          canvas.width = video.clientWidth;
          canvas.height = video.clientHeight;
          isProcessing = true;
          processFrame();
        }
      });

      video.addEventListener("ended", () => {
        isProcessing = false;
      });

      // --- 4. CORE PROCESSING LOOP (Supports both Worker and Main Thread) ---
      async function processFrame() {
        if (!isProcessing || video.ended) return;
        if (useWebWorker && !isWorkerReady) return;
        if (!useWebWorker && !session) return;

        const frameStart = performance.now();

        try {
          // Capture frame from video
          const offScreenCanvas = document.createElement("canvas");
          offScreenCanvas.width = MODEL_INPUT_SIZE;
          offScreenCanvas.height = MODEL_INPUT_SIZE;
          const tempCtx = offScreenCanvas.getContext("2d");
          tempCtx.drawImage(video, 0, 0, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE);
          const imageData = tempCtx.getImageData(
            0,
            0,
            MODEL_INPUT_SIZE,
            MODEL_INPUT_SIZE
          );

          if (useWebWorker) {
            // Web Worker Mode - use job queue
            enqueueJob({
              data: Array.from(imageData.data),
              width: imageData.width,
              height: imageData.height,
            });

            // Log stats periodically
            if (frameIdCounter % 30 === 0) {
              console.log(
                `[Worker] Stats: ${jobQueue.length} queued, ${
                  processingJobs.size
                } processing, ${
                  lastDisplayedFrameId + 1
                }/${frameIdCounter} displayed`
              );
            }
          } else {
            // Main Thread Mode - process directly
            const inputTensor = preprocessOnMainThread(imageData);

            const inferenceStart = performance.now();
            const feeds = {};
            feeds[session.inputNames[0]] = inputTensor;
            const results = await session.run(feeds);
            const inferenceTime = (performance.now() - inferenceStart).toFixed(
              2
            );

            const outputName = session.outputNames[0];
            const outputTensor = results[outputName];

            drawDetections(outputTensor);

            const totalTime = (performance.now() - frameStart).toFixed(2);

            if (frameIdCounter++ % 30 === 0) {
              console.log(
                `[Main Thread] Frame processed in ${totalTime}ms (Inference: ${inferenceTime}ms)`
              );
            }
          }
        } catch (err) {
          console.error("Frame processing error:", err);
        }

        // Continue loop
        requestAnimationFrame(processFrame);
      }

      // Preprocessing for main thread
      function preprocessOnMainThread(imageData) {
        const { data } = imageData;
        const float32Data = new Float32Array(
          3 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE
        );

        for (let i = 0; i < data.length / 4; i++) {
          const r = data[i * 4] / 255.0;
          const g = data[i * 4 + 1] / 255.0;
          const b = data[i * 4 + 2] / 255.0;
          float32Data[i] = r;
          float32Data[i + MODEL_INPUT_SIZE * MODEL_INPUT_SIZE] = g;
          float32Data[i + 2 * MODEL_INPUT_SIZE * MODEL_INPUT_SIZE] = b;
        }

        return new ort.Tensor("float32", float32Data, [
          1,
          3,
          MODEL_INPUT_SIZE,
          MODEL_INPUT_SIZE,
        ]);
      }

      // --- 5. PRE-PROCESSING (Moved to Worker) ---
      // Preprocessing now happens in detection-worker.js for parallel processing

      // --- 6. POST-PROCESSING (YOLOv11/v8 Logic) ---
      function drawDetections(output) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        const data = output.data;
        const dims = output.dims; // [1, 84, 8400]
        const numClasses = dims[1] - 4;
        const numAnchors = dims[2];

        const scaleX = canvas.width / MODEL_INPUT_SIZE;
        const scaleY = canvas.height / MODEL_INPUT_SIZE;

        const boxes = [];

        for (let i = 0; i < numAnchors; i++) {
          let maxScore = -Infinity;
          let classIndex = -1;

          for (let c = 0; c < numClasses; c++) {
            const row = c + 4;
            const score = data[row * numAnchors + i];
            if (score > maxScore) {
              maxScore = score;
              classIndex = c;
            }
          }

          if (maxScore > CONFIDENCE_THRESHOLD) {
            // FILTER: Only allow Person (0) and Sports Ball (32)
            // if (classIndex === 0 || classIndex === 32) {
            const cx = data[0 * numAnchors + i];
            const cy = data[1 * numAnchors + i];
            const w = data[2 * numAnchors + i];
            const h = data[3 * numAnchors + i];

            const x1 = (cx - w / 2) * scaleX;
            const y1 = (cy - h / 2) * scaleY;
            const x2 = (cx + w / 2) * scaleX;
            const y2 = (cy + h / 2) * scaleY;

            boxes.push([x1, y1, x2, y2, classIndex, maxScore]);
            // }
          }
        }

        const selectedBoxes = nms(boxes, 0.45);

        selectedBoxes.forEach((box) => {
          const [x1, y1, x2, y2, classIdx, score] = box;
          const color = getColor(classIdx);
          const labelName = labels[classIdx] || "Unknown";

          ctx.strokeStyle = color;
          ctx.lineWidth = 3;
          ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

          const text = `${labelName} ${(score * 100).toFixed(1)}%`;
          ctx.font = "16px Arial";
          const textWidth = ctx.measureText(text).width;
          ctx.fillStyle = color;
          ctx.fillRect(x1, y1 - 20, textWidth + 10, 20);
          ctx.fillStyle = "#FFFFFF";
          ctx.fillText(text, x1 + 5, y1 - 5);
        });
      }

      function nms(boxes, iouThreshold) {
        if (boxes.length === 0) return [];
        boxes.sort((a, b) => b[5] - a[5]);
        const result = [];
        while (boxes.length > 0) {
          const best = boxes.shift();
          result.push(best);
          boxes = boxes.filter(
            (other) => calculateIoU(best, other) < iouThreshold
          );
        }
        return result;
      }

      function calculateIoU(boxA, boxB) {
        const xA = Math.max(boxA[0], boxB[0]);
        const yA = Math.max(boxA[1], boxB[1]);
        const xB = Math.min(boxA[2], boxB[2]);
        const yB = Math.min(boxA[3], boxB[3]);
        const intersectionArea = Math.max(0, xB - xA) * Math.max(0, yB - yA);
        const areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]);
        const areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]);
        return intersectionArea / (areaA + areaB - intersectionArea);
      }

      function getColor(index) {
        const colors = [
          "#FF0000",
          "#00FF00",
          "#0000FF",
          "#000000",
          "#00FFFF",
          "#FF00FF",
          "#FFA500",
        ];
        return colors[index % colors.length];
      }
    </script>
  </body>
</html>
